<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Blind one-microphone speech separation: A spectral learning approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
							<email>fbach@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science and Statistics</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
								<address>
									<postCode>94720, 94720</postCode>
									<region>CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
							<email>jordan@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science and Statistics</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
								<address>
									<postCode>94720, 94720</postCode>
									<region>CA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Blind one-microphone speech separation: A spectral learning approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an algorithm to perform blind, one-microphone speech separation. Our algorithm separates mixtures of speech without modeling individual speakers. Instead, we formulate the problem of speech separation as a problem in segmenting the spectrogram of the signal into two or more disjoint sets. We build feature sets for our segmenter using classical cues from speech psychophysics. We then combine these features into parameterized affinity matrices. We also take advantage of the fact that we can generate training examples for segmentation by artificially superposing separately-recorded signals. Thus the parameters of the affinity matrices can be tuned using recent work on learning spectral clustering [1]. This yields an adaptive, speech-specific segmentation algorithm that can successfully separate one-microphone speech mixtures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
