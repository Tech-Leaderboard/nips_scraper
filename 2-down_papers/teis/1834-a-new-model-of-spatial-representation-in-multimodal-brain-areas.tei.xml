<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A new model of spatial representations multimodal brain areas.. In</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Deneve</surname></persName>
							<email>sdeneve@bcs.rochester.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Brain and cognitive Science</orgName>
								<orgName type="department" key="dep2">Department of Brain and Cognitive University of Rochester Rochester</orgName>
								<orgName type="laboratory">Institut des Sciences Cognitives C.N.R.S Bron</orgName>
								<orgName type="institution">University of Rochester Rochester</orgName>
								<address>
									<postCode>14620., 69675, 14620</postCode>
									<region>NY, NY</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Rene</forename><surname>Duhamel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Brain and cognitive Science</orgName>
								<orgName type="department" key="dep2">Department of Brain and Cognitive University of Rochester Rochester</orgName>
								<orgName type="laboratory">Institut des Sciences Cognitives C.N.R.S Bron</orgName>
								<orgName type="institution">University of Rochester Rochester</orgName>
								<address>
									<postCode>14620., 69675, 14620</postCode>
									<region>NY, NY</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Pouget</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Brain and cognitive Science</orgName>
								<orgName type="department" key="dep2">Department of Brain and Cognitive University of Rochester Rochester</orgName>
								<orgName type="laboratory">Institut des Sciences Cognitives C.N.R.S Bron</orgName>
								<orgName type="institution">University of Rochester Rochester</orgName>
								<address>
									<postCode>14620., 69675, 14620</postCode>
									<region>NY, NY</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A new model of spatial representations multimodal brain areas.. In</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocen-tric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsycholog-ical data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
