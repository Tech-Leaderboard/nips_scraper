<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Total Variation Classes Beyond 1d: Minimax Rates, and the Limitations of Linear Smoothers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veeranjaneyulu</forename><surname>Sadhanala</surname></persName>
							<email>vsadhana@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Department</orgName>
								<orgName type="department" key="dep2">Machine Learning Department Carnegie</orgName>
								<orgName type="department" key="dep3">Department of Statistics Carnegie</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit3">Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213, 15213, 15213</postCode>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
							<email>yuxiangw@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Department</orgName>
								<orgName type="department" key="dep2">Machine Learning Department Carnegie</orgName>
								<orgName type="department" key="dep3">Department of Statistics Carnegie</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit3">Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213, 15213, 15213</postCode>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Department</orgName>
								<orgName type="department" key="dep2">Machine Learning Department Carnegie</orgName>
								<orgName type="department" key="dep3">Department of Statistics Carnegie</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit3">Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213, 15213, 15213</postCode>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Total Variation Classes Beyond 1d: Minimax Rates, and the Limitations of Linear Smoothers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of estimating a function defined over n locations on a d-dimensional grid (having all side lengths equal to n 1/d). When the function is constrained to have discrete total variation bounded by C n , we derive the minimax optimal (squared) 2 estimation error rate, parametrized by n, C n. Total variation denoising, also known as the fused lasso, is seen to be rate optimal. Several simpler estimators exist, such as Laplacian smoothing and Laplacian eigenmaps. A natural question is: can these simpler estimators perform just as well? We prove that these estimators, and more broadly all estimators given by linear transformations of the input data, are suboptimal over the class of functions with bounded variation. This extends fundamental findings of Donoho and Johnstone [12] on 1-dimensional total variation spaces to higher dimensions. The implication is that the computationally simpler methods cannot be used for such sophisticated denoising tasks, without sacrificing statistical accuracy. We also derive minimax rates for discrete Sobolev spaces over d-dimensional grids, which are, in some sense, smaller than the total variation function spaces. Indeed, these are small enough spaces that linear estima-tors can be optimal-and a few well-known ones are, such as Laplacian smoothing and Laplacian eigenmaps, as we show. Lastly, we investigate the adaptivity of the total variation denoiser to these smaller Sobolev function spaces.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
