<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Measuring Neural Net Robustness with Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osbert</forename><surname>Bastani</surname></persName>
							<email>obastani@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yani</forename><surname>Ioannou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Lampropoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Vytiniotis</surname></persName>
							<email>dimitris@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">V</forename><surname>Nori</surname></persName>
							<email>adityan@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<orgName type="institution" key="instit3">University of Pennsylvania</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">Microsoft Research</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Measuring Neural Net Robustness with Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Despite having high accuracy, neural nets have been shown to be susceptible to adversarial examples, where a small perturbation to an input can cause it to become mislabeled. We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program. We show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the MNIST and CIFAR-10 datasets. Our algorithm generates more informative estimates of robustness metrics compared to estimates based on existing algorithms. Furthermore, we show how existing approaches to improving robustness &quot;overfit&quot; to adversarial examples generated using a specific algorithm. Finally, we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose, but also according to previously proposed metrics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
