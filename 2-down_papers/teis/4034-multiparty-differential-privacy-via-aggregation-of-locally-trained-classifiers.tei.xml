<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manas</forename><forename type="middle">A</forename><surname>Pathak</surname></persName>
							<email>manasp@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Mitsubishi Electric Research Labs Cambridge</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, MA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Rane</surname></persName>
							<email>rane@merl.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Mitsubishi Electric Research Labs Cambridge</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, MA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
							<email>bhiksha@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Mitsubishi Electric Research Labs Cambridge</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, MA, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As increasing amounts of sensitive personal information finds its way into data repositories, it is important to develop analysis mechanisms that can derive aggregate information from these repositories without revealing information about individual data instances. Though the differential privacy model provides a framework to analyze such mechanisms for databases belonging to a single party, this framework has not yet been considered in a multi-party setting. In this paper, we propose a privacy-preserving protocol for composing a differentially private aggregate classifier using classifiers trained locally by separate mutually untrusting parties. The protocol allows these parties to interact with an untrusted curator to construct additive shares of a perturbed aggregate classifier. We also present a detailed theoretical analysis containing a proof of differential privacy of the perturbed aggregate classifier and a bound on the excess risk introduced by the perturbation. We verify the bound with an experimental evaluation on a real dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
