<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Filter Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>De Brabandere</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="department" key="dep2">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="laboratory">ESAT-PSI, KU Leuven, iMinds D-ITET, ETH Zurich</orgName>
								<orgName type="institution">ESAT-PSI, KU Leuven</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="department" key="dep2">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="laboratory">ESAT-PSI, KU Leuven, iMinds D-ITET, ETH Zurich</orgName>
								<orgName type="institution">ESAT-PSI, KU Leuven</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="department" key="dep2">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="laboratory">ESAT-PSI, KU Leuven, iMinds D-ITET, ETH Zurich</orgName>
								<orgName type="institution">ESAT-PSI, KU Leuven</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="department" key="dep2">ESAT-PSI, KU Leuven, iMinds</orgName>
								<orgName type="laboratory">ESAT-PSI, KU Leuven, iMinds D-ITET, ETH Zurich</orgName>
								<orgName type="institution">ESAT-PSI, KU Leuven</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic Filter Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
