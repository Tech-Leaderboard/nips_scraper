<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoli</forename><surname>Juditsky</surname></persName>
							<email>anatoli.iouditski@imag.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Nazin</surname></persName>
							<email>nazine@ipu.rssi.ru</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Tsybakov</surname></persName>
							<email>tsybakov@ccr.jussieu.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Vayatis</surname></persName>
							<email>vayatis@ccr.jussieu.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Control Sciences -Russian Academy of Science</orgName>
								<orgName type="laboratory">Laboratoire de Modélisation et Calcul</orgName>
								<orgName type="institution">Université Grenoble I B.P. 53</orgName>
								<address>
									<addrLine>65, Profsoyuznaya str., GSP-7, Moscow</addrLine>
									<postCode>38041, 117997</postCode>
									<settlement>Grenoble</settlement>
									<country>France, Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratoire de Probabilités et Modèles Aléatoires -Université</orgName>
								<address>
									<addrLine>Paris VI 4, place Jussieu</addrLine>
									<postCode>75252</postCode>
									<settlement>Paris Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Laboratoire de Probabilités et Modèles Aléatoires -Université</orgName>
								<address>
									<addrLine>Paris VI 4, place Jussieu</addrLine>
									<postCode>75252</postCode>
									<settlement>Paris Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of constructing an aggregated estimator from a finite class of base functions which approximately minimizes a convex risk functional under the ℓ 1 constraint. For this purpose, we propose a stochastic procedure, the mirror descent, which performs gradient descent in the dual space. The generated estimates are additionally averaged in a recursive fashion with specific weights. Mirror descent algorithms have been developed in different contexts and they are known to be particularly efficient in high dimensional problems. Moreover their implementation is adapted to the online setting. The main result of the paper is the upper bound on the convergence rate for the generalization error.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
