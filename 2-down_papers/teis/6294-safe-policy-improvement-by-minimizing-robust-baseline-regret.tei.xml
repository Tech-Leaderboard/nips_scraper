<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Safe Policy Improvement by Minimizing Robust Baseline Regret</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Petrik</surname></persName>
							<email>mpetrik@cs.unh.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Adobe Research &amp; INRIA Lille</orgName>
								<orgName type="institution" key="instit1">University of New Hampshire</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Ghavamzadeh</surname></persName>
							<email>ghavamza@adobe.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Adobe Research &amp; INRIA Lille</orgName>
								<orgName type="institution" key="instit1">University of New Hampshire</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinlam</forename><surname>Chow</surname></persName>
							<email>ychow@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Adobe Research &amp; INRIA Lille</orgName>
								<orgName type="institution" key="instit1">University of New Hampshire</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Safe Policy Improvement by Minimizing Robust Baseline Regret</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>An important problem in sequential decision-making under uncertainty is to use limited data to compute a safe policy, which is guaranteed to outperform a given baseline strategy. In this paper, we develop and analyze a new model-based approach that computes a safe policy, given an inaccurate model of the system&apos;s dynamics and guarantees on the accuracy of this model. The new robust method uses this model to directly minimize the (negative) regret w.r.t. the baseline policy. Contrary to existing approaches, minimizing the regret allows one to improve the baseline policy in states with accurate dynamics and to seamlessly fall back to the baseline policy, otherwise. We show that our formulation is NP-hard and propose a simple approximate algorithm. Our empirical results on several domains further show that even the simple approximate algorithm can outperform standard approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
