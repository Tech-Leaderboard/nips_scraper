<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Memory Limited, Streaming PCA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
							<email>ioannis@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Microsoft Research Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Caramanis</surname></persName>
							<email>constantine@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Microsoft Research Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Jain</surname></persName>
							<email>prajain@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit3">Microsoft Research Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Memory Limited, Streaming PCA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider streaming, one-pass principal component analysis (PCA), in the high-dimensional regime, with limited memory. Here, p-dimensional samples are presented sequentially, and the goal is to produce the k-dimensional subspace that best approximates these points. Standard algorithms require O(p 2) memory; meanwhile no algorithm can do better than O(kp) memory, since this is what the output itself requires. Memory (or storage) complexity is most meaningful when understood in the context of computational and sample complexity. Sample complexity for high-dimensional PCA is typically studied in the setting of the spiked covariance model, where p-dimensional points are generated from a population covariance equal to the identity (white noise) plus a low-dimensional perturbation (the spike) which is the signal to be recovered. It is now well-understood that the spike can be recovered when the number of samples, n, scales proportionally with the dimension, p. Yet, all algorithms that provably achieve this, have memory complexity O(p 2). Meanwhile, algorithms with memory-complexity O(kp) do not have provable bounds on sample complexity comparable to p. We present an algorithm that achieves both: it uses O(kp) memory (meaning storage of any kind) and is able to compute the k-dimensional spike with O(p log p) sample-complexity-the first algorithm of its kind. While our theoretical analysis focuses on the spiked covariance model, our simulations show that our algorithm is successful on much more general models for the data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
