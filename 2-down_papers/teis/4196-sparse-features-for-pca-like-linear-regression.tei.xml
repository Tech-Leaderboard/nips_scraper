<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse Features for PCA-Like Linear Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Boutsidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Mathematical Sciences Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="department" key="dep3">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<orgName type="institution" key="instit3">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180, 12180</postCode>
									<region>New York, NY, NY</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petros</forename><surname>Drineas</surname></persName>
							<email>drinep@cs.rpi.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Mathematical Sciences Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="department" key="dep3">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<orgName type="institution" key="instit3">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180, 12180</postCode>
									<region>New York, NY, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Magdon-Ismail</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Mathematical Sciences Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="department" key="dep3">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">IBM T. J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<orgName type="institution" key="instit3">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<postCode>12180, 12180</postCode>
									<region>New York, NY, NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse Features for PCA-Like Linear Regression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Principal Components Analysis (PCA) is often used as a feature extraction procedure. Given a matrix X ∈ R n×d , whose rows represent n data points with respect to d features, the top k right singular vectors of X (the so-called eigenfeatures), are arbitrary linear combinations of all available features. The eigenfeatures are very useful in data analysis, including the regularization of linear regression. Enforcing sparsity on the eigenfeatures, i.e., forcing them to be linear combinations of only a small number of actual features (as opposed to all available features), can promote better generalization error and improve the interpretability of the eigen-features. We present deterministic and randomized algorithms that construct such sparse eigenfeatures while provably achieving in-sample performance comparable to regularized linear regression. Our algorithms are relatively simple and practically efficient, and we demonstrate their performance on several data sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
