<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VLSI Implementations of Learning and Memory Systems: A Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Holler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Intel Corporation</orgName>
								<orgName type="institution" key="instit2">Mission College Blvd. Santa Clara</orgName>
								<address>
									<postCode>2250, 95052-8125</postCode>
									<settlement>Ca</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">VLSI Implementations of Learning and Memory Systems: A Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A large number of VLSI implementations of neural network models have been reported. The diversity of these implementations is noteworthy. This paper attempts to put a group of representative VLSI implementations in perspective by comparing and contrasting them. Design trade-offs are discussed and some suggestions forthe direction of future implementation efforts are made. IMPLEMENTATION Changing the way information is represented can be beneficial. For example a change of representation can make information more compact for storage and transmission. Implementation of neural computational models is just the process of changing the representation of a neural model from mathmatical symbolism to a physical embodi-ement for the purpose of shortening the time it takes to process information according to the neural model. FLEXIBIliTY VS. PERFORMANCE Today most neural models are already implemented in silicon VLSI, in the form of programs running on general purpose digital von Neumann computers. These machines are available at low cost and are highly flexible. Their flexibility results from the ease with which their programs can be changed. Maximizing flexibility, however, usually results in reduced performance. A program will often have to specify several simple op-993</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
