<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Code-specific policy gradient rules for spiking neurons</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Sprekeler</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory for Computational NeurosciencéNeurosciencé Ecole Polytechnique Fédérale de Lausanne</orgName>
								<address>
									<postCode>1015</postCode>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Hennequin</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory for Computational NeurosciencéNeurosciencé Ecole Polytechnique Fédérale de Lausanne</orgName>
								<address>
									<postCode>1015</postCode>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wulfram</forename><surname>Gerstner</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory for Computational NeurosciencéNeurosciencé Ecole Polytechnique Fédérale de Lausanne</orgName>
								<address>
									<postCode>1015</postCode>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Code-specific policy gradient rules for spiking neurons</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Although it is widely believed that reinforcement learning is a suitable tool for describing behavioral learning, the mechanisms by which it can be implemented in networks of spiking neurons are not fully understood. Here, we show that different learning rules emerge from a policy gradient approach depending on which features of the spike trains are assumed to influence the reward signals, i.e., depending on which neural code is in effect. We use the framework of Williams (1992) to derive learning rules for arbitrary neural codes. For illustration, we present policy-gradient rules for three different example codes-a spike count code, a spike timing code and the most general &quot;full spike train&quot; code-and test them on simple model problems. In addition to classical synaptic learning, we derive learning rules for intrinsic parameters that control the excitability of the neuron. The spike count learning rule has structural similarities with established Bienenstock-Cooper-Munro rules. If the distribution of the relevant spike train features belongs to the natural exponential family, the learning rules have a characteristic shape that raises interesting prediction problems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
