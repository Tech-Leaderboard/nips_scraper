<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical spike coding of sound</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>December 3-6, 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Karklin</surname></persName>
							<email>yan.karklin@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Neural Science</orgName>
								<orgName type="department" key="dep2">Center for Neural Science, and Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit1">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<orgName type="institution" key="instit3">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Ekanadham</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Neural Science</orgName>
								<orgName type="department" key="dep2">Center for Neural Science, and Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit1">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<orgName type="institution" key="instit3">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eero</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
							<email>eero.simoncelli@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Neural Science</orgName>
								<orgName type="department" key="dep2">Center for Neural Science, and Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit1">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<orgName type="institution" key="instit3">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical spike coding of sound</title>
					</analytic>
					<monogr>
						<title level="m">Neural Information Processing Systems (NIPS)</title>
						<meeting> <address><addrLine>Lake Tahoe, Nevada</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">December 3-6, 2012</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Natural sounds exhibit complex statistical regularities at multiple scales. Acoustic events underlying speech, for example, are characterized by precise temporal and frequency relationships, but they can also vary substantially according to the pitch, duration, and other high-level properties of speech production. Learning this structure from data while capturing the inherent variability is an important first step in building auditory processing systems, as well as understanding the mechanisms of auditory perception. Here we develop Hierarchical Spike Coding, a two-layer probabilistic generative model for complex acoustic structure. The first layer consists of a sparse spiking representation that encodes the sound using kernels positioned precisely in time and frequency. Patterns in the positions of first layer spikes are learned from the data: on a coarse scale, statistical regularities are encoded by a second-layer spiking representation, while fine-scale structure is captured by recurrent interactions within the first layer. When fit to speech data, the second layer acoustic features include harmonic stacks, sweeps, frequency modulations, and precise temporal onsets, which can be composed to represent complex acoustic events. Unlike spectrogram-based methods, the model gives a probability distribution over sound pressure waveforms. This allows us to use the second-layer representation to synthesize sounds directly, and to perform model-based denoising, on which we demonstrate a significant improvement over standard methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
