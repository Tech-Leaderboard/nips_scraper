<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse Embedded k-Means Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Centre for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">The University of New South Wales ‡ School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
								<orgName type="institution" key="instit3">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Centre for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">The University of New South Wales ‡ School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
								<orgName type="institution" key="instit3">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
							<email>ivor.tsang@uts.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Centre for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">The University of New South Wales ‡ School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
								<orgName type="institution" key="instit3">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse Embedded k-Means Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The k-means clustering algorithm is a ubiquitous tool in data mining and machine learning that shows promising performance. However, its high computational cost has hindered its applications in broad domains. Researchers have successfully addressed these obstacles with dimensionality reduction methods. Recently, [1] develop a state-of-the-art random projection (RP) method for faster k-means clustering. Their method delivers many improvements over other dimensionality reduction methods. For example, compared to the advanced singular value decomposition based feature extraction approach, [1] reduce the running time by a factor of min{n, d} 2 log(d)/k for data matrix X ∈ R n×d with n data points and d features, while losing only a factor of one in approximation accuracy. Unfortunately , they still require O(ndk 2 log(d)) for matrix multiplication and this cost will be prohibitive for large values of n and d. To break this bottleneck, we carefully build a sparse embedded k-means clustering algorithm which requires O(nnz(X)) (nnz(X) denotes the number of non-zeros in X) for fast matrix multiplication. Moreover, our proposed algorithm improves on [1]&apos;s results for approximation accuracy by a factor of one. Our empirical studies corroborate our theoretical findings , and demonstrate that our approach is able to significantly accelerate k-means clustering, while achieving satisfactory clustering performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
