<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Shepanski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">TRW, Inc . One Space Park</orgName>
								<address>
									<postCode>02/1779, 90278</postCode>
									<settlement>Redondo Beach</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Macy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">TRW, Inc . One Space Park</orgName>
								<address>
									<postCode>02/1779, 90278</postCode>
									<settlement>Redondo Beach</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Abetract 693 We have developed a methodology for manually training autononlous control systems based on artificial neural systems (ANS). In applications where the rule set governing an expert&apos;s decisions is difficult to formulate, ANS can be used to ext.ra.c:t rules by associating the information an expert receives with the actions h~ takes. Properly constructed networks imitate rules of behavior that permits them to function autonomously when they are trained on the spanning set of possible situations. This training can be provided manually, either under the direct. supervision or a system trainer, or indirectly using a background mode where the network assimilates training data as the expert perrorms his day-today tasks. To demonstrate these methods we have trained an ANS network to drive a vehicle through simulated rreeway traffic. I ntJooducticn Computational systems employing fine grained parallelism are revolutionizing the way we approach a number or long standing problems involving pattern recognition and cognitive processing. The field spans a wide variety or computational networks, rrom constructs emulating neural runctions, to more crystalline configurations that resemble systolic arrays. Several titles are used to describe this broad area or research, we use the term artificial neural systems (ANS). Our concern in this work is the use or ANS ror manually training certain types or autonomous systems where the desired rules of behavior are difficult to rormulate. Artificial neural systems consist of a number or processing elements interconnected in a weighted, user-specified fashion, the interconnection weights acting as memory ror the system. Each processing element calculatE&apos;,&gt; an output value based on the weighted sum or its inputs. In addition, the input data is correlated with the output or desired output (specified by an instructive agent) in a training rule that is used to adjust the interconnection weights. In this way the ne~ work learns patterns or imitates rules of behavior and decision making. The partiCUlar ANS architecture we use is a variation of Rummelhart et. al. [lJ multi-layer perceptron employing the generalized delta rule (GD R). Instead of a single, multi-layer ,struc-ture, our final network has a a multiple component or &quot;block&quot; configuration where one blOt&apos;k&apos;~ output reeds into another (see Figure 3). The training methodology we have developed is not tied to a particular training rule or architecture and should work well with alternative networks like Grossberg&apos;s adaptive resonance model[2J.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
