<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Task Learning for Contextual Bandits</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><forename type="middle">Anand</forename><surname>Deshmukh</surname></persName>
							<email>aniketde@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department</orgName>
								<orgName type="institution">EECS University of Michigan</orgName>
								<address>
									<addrLine>Ann Arbor Ann Arbor</addrLine>
									<postCode>48105</postCode>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urun</forename><surname>Dogan</surname></persName>
							<email>urun.dogan@skype.net</email>
							<affiliation key="aff1">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<postCode>CB1 2FB</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<addrLine>Ann Arbor Ann Arbor</addrLine>
									<postCode>48105</postCode>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Task Learning for Contextual Bandits</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Contextual bandits are a form of multi-armed bandit in which the agent has access to predictive side information (known as the context) for each arm at each time step, and have been used to model personalized news recommendation, ad placement, and other applications. In this work, we propose a multi-task learning framework for contextual bandit problems. Like multi-task learning in the batch setting, the goal is to leverage similarities in contexts for different arms so as to improve the agent&apos;s ability to predict rewards from contexts. We propose an upper confidence bound-based multi-task learning algorithm for contextual bandits, establish a corresponding regret bound, and interpret this bound to quantify the advantages of learning in the presence of high task (arm) similarity. We also describe an effective scheme for estimating task similarity from data, and demonstrate our algorithm&apos;s performance on several data sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
