<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SCALING AND GENERALIZATION IN NEURAL NETWORKS: A CASE STUDY</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Complex Systems Research</orgName>
								<orgName type="department" key="dep2">IBM Watson Research Center</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>508 S. 6th St</addrLine>
									<postBox>PO Box 704</postBox>
									<postCode>61820 ABSTRACT, 10598</postCode>
									<settlement>Champaign, Yorktown Heights</settlement>
									<region>IL, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Complex Systems Research</orgName>
								<orgName type="department" key="dep2">IBM Watson Research Center</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>508 S. 6th St</addrLine>
									<postBox>PO Box 704</postBox>
									<postCode>61820 ABSTRACT, 10598</postCode>
									<settlement>Champaign, Yorktown Heights</settlement>
									<region>IL, NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SCALING AND GENERALIZATION IN NEURAL NETWORKS: A CASE STUDY</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>160</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The issues of scaling and generalization have emerged as key issues in current studies of supervised learning from examples in neural networks. Questions such as how many training patterns and training cycles are needed for a problem of a given size and difficulty, how to represent the inllUh and how to choose useful training exemplars, are of considerable theoretical and practical importance. Several intuitive rules of thumb have been obtained from empirical studies, but as yet there are few rigorous results. In this paper we summarize a study Qf generalization in the simplest possible case-perceptron networks learning linearly separable functions. The task chosen was the majority function (i.e. return a 1 if a majority of the input units are on), a predicate with a number of useful properties. We find that many aspects of.generalization in multilayer networks learning large, difficult tasks are reproduced in this simple domain, in which concrete numerical results and even some analytic understanding can be achieved.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
