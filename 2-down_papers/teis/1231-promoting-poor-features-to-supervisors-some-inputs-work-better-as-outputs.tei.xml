<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Promoting Poor Features to Supervisors: Some Inputs Work Better as Outputs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
							<email>caruana@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Sloan Center for Theoretical Neurobiology and W . M. Keck Center for Integrative Neuroscience University of California</orgName>
								<orgName type="institution">JPRC and Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213, 94143</postCode>
									<settlement>San Francisco</settlement>
									<region>PA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><forename type="middle">R</forename><surname>De Sa</surname></persName>
							<email>desa@phy.ucsf.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Sloan Center for Theoretical Neurobiology and W . M. Keck Center for Integrative Neuroscience University of California</orgName>
								<orgName type="institution">JPRC and Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213, 94143</postCode>
									<settlement>San Francisco</settlement>
									<region>PA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Promoting Poor Features to Supervisors: Some Inputs Work Better as Outputs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In supervised learning there is usually a clear distinction between inputs and outputs-inputs are what you will measure, outputs are what you will predict from those measurements. This paper shows that the distinction between inputs and outputs is not this simple. Some features are more useful as extra outputs than as inputs. By using a feature as an output we get more than just the case values but can. learn a mapping from the other inputs to that feature. For many features this mapping may be more useful than the feature value itself. We present two regression problems and one classification problem where performance improves if features that could have been used as inputs are used as extra outputs instead. This result is surprising since a feature used as an output is not used during testing.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
