<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Minimum Volume Sets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
							<email>cscott@rice.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Statistics Department</orgName>
								<orgName type="department" key="dep2">Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Rice University Houston</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin Madison</orgName>
								<address>
									<postCode>77005, 53706</postCode>
									<region>TX, WI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nowak</surname></persName>
							<email>nowak@engr.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Statistics Department</orgName>
								<orgName type="department" key="dep2">Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Rice University Houston</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin Madison</orgName>
								<address>
									<postCode>77005, 53706</postCode>
									<region>TX, WI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Minimum Volume Sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Given a probability measure P and a reference measure µ, one is often interested in the minimum µ-measure set with P-measure at least α. Minimum volume sets of this type summarize the regions of greatest probability mass of P , and are useful for detecting anomalies and constructing confidence regions. This paper addresses the problem of estimating minimum volume sets based on independent samples distributed according to P. Other than these samples, no other information is available regarding P , but the reference measure µ is assumed to be known. We introduce rules for estimating minimum volume sets that parallel the empirical risk minimization and structural risk minimization principles in classification. As in classification, we show that the performances of our estimators are controlled by the rate of uniform convergence of empirical to true probabilities over the class from which the estimator is drawn. Thus we obtain finite sample size performance bounds in terms of VC dimension and related quantities. We also demonstrate strong universal consistency and an oracle inequality. Estimators based on histograms and dyadic partitions illustrate the proposed rules.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
