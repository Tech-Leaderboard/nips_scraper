<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning in Computer Vision and Image Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>116-81, 91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning in Computer Vision and Image Understanding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There is an increasing interest in the area of Learning in Computer Vision and Image Understanding, both from researchers in the learning community and from researchers involved with the computer vision world. The field is characterized by a shift away from the classical, purely model-based, computer vision techniques, towards data-driven learning paradigms for solving real-world vision problems. Using learning in segmentation or recognition tasks has several advantages over classical model-based techniques. These include adaptivity to noise and changing environments, as well as in many cases, a simplified system generation procedure. Yet, learning from examples introduces a new challenge-getting a representative data set of examples from which to learn. Applications of learning systems to practical problems have shown that the performance of the system is often critically dependent on both the size and quality of the training set. Federico Girosi of MIT suggested the use of prior information as a general method for synthesizing many training examples from few exemplars. Prototypical transformations are used for general 3D object recognition. Face-recognition was presented as a particular example. Dean Pomerleau of Carnegie Mellon addressed the training data problem as well, within the context of ALVINN, a neural network vision system which drives an autonomous van without human intervention. Some general problems emerge, such as getting sufficient training data for the more unexpected scenes including passing cars and intersections. Several techniques for exploiting prior geometric knowledge during training and testing of the neural-network, were presented. A somewhat different perspective was presented by Bartlett Mel of Caltech. Bartlett introduced a 3D object recognition approach based on concepts from the human visual system. Here the assumption is that a large database of examples exists, with varying viewing angles and distances, as is available to human observers as they manipulate and inspect common objects. A different issue of interest was using learning schemes in general recognition frameworks which can handle several different vision problems. Hayit Greenspan of Caltech suggested combining unsupervised and supervised learning approaches within a multiresolution image representation space, for texture and shape recognition. It was suggested that shifting the input pixel representation to a more robust representation (using a pyramid filtering approach) in combination with learning 1182</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
