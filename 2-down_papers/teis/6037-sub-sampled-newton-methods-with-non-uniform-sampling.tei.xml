<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sub-sampled Newton Methods with Non-uniform Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
							<email>pengxu@stanford.edu jiyan@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farbod</forename><surname>Roosta-Khorasani</surname></persName>
							<email>farbod@icsi.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
							<email>mmahoney@stat.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sub-sampled Newton Methods with Non-uniform Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of finding the minimizer of a convex function F : R d → R of the form F (w) := n i=1 f i (w) + R(w) where a low-rank factorization of 2 f i (w) is readily available. We consider the regime where n d. We propose randomized Newton-type algorithms that exploit non-uniform sub-sampling of {{ 2 f i (w)} n i=1 , as well as inexact updates, as means to reduce the computational complexity, and are applicable to a wide range of problems in machine learning. Two non-uniform sampling distributions based on block norm squares and block partial leverage scores are considered. Under certain assumptions, we show that our algorithms inherit a linear-quadratic convergence rate in w and achieve a lower computational complexity compared to similar existing methods. In addition, we show that our algorithms exhibit more robustness and better dependence on problem specific quantities, such as the condition number. We empirically demonstrate that our methods are at least twice as fast as Newton&apos;s methods on several real datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
