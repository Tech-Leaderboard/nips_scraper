<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse Linear Programming via Primal and Dual Augmented Coordinate Descent</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">E H</forename><surname>Yen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">University of California at Davis</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse Linear Programming via Primal and Dual Augmented Coordinate Descent</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Over the past decades, Linear Programming (LP) has been widely used in different areas and considered as one of the mature technologies in numerical optimization. However, the complexity offered by state-of-the-art algorithms (i.e. interior-point method and primal, dual simplex methods) is still unsatisfactory for problems in machine learning with huge number of variables and constraints. In this paper, we investigate a general LP algorithm based on the combination of Augmented Lagrangian and Coordinate Descent (AL-CD), giving an iteration complexity of O((log(1//)) 2) with O(nnz(A)) cost per iteration, where nnz(A) is the number of non-zeros in the m × n constraint matrix A, and in practice, one can further reduce cost per iteration to the order of non-zeros in columns (rows) corresponding to the active primal (dual) variables through an active-set strategy. The algorithm thus yields a tractable alternative to standard LP methods for large-scale problems of sparse solutions and nnz(A) mn. We conduct experiments on large-scale LP instances from 1-regularized multi-class SVM, Sparse Inverse Covariance Estimation , and Nonnegative Matrix Factorization, where the proposed approach finds solutions of 10 −3 precision orders of magnitude faster than state-of-the-art implementations of interior-point and simplex methods. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
