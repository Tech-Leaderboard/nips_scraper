<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Agnostic PAC-Learning of Functions on Analog Neural Nets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
							<email>e-mail: maass@igi.tu-graz.ac.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Theoretical Computer Science Technische</orgName>
								<orgName type="institution">Universitaet Graz</orgName>
								<address>
									<addrLine>Klosterwiesgasse 32/2 A-BOlO Graz</addrLine>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Agnostic PAC-Learning of Functions on Analog Neural Nets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>(Extended Abstract)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There exist a number of negative results ([J), [BR), [KV]) about learning on neural nets in Valiant&apos;s model [V) for probably approximately correct learning (&quot;PAC-learning&quot;). These negative results are based on an asymptotic analysis where one lets the number of nodes in the neural net go to infinit.y. Hence this analysis is less adequate for the investigation of learning on a small fixed neural net. with relatively few analog inputs (e.g. the principal components of some sensory data). The latter type of learning problem gives rise to a different kind of asymptotic question: Can the true error of the neural net be brought arbitrarily close to that of a neural net with &quot;optimal&quot; weights through sufficiently long training? In this paper we employ some new arguments ill order to give a positive answer to this question in Haussler&apos;s rather realistic refinement of Valiant&apos;s model for PAC-learning ([H), [KSS)). In this more realistic model no a-priori assumptions are required about the &quot;learning target&quot; , noise is permitted in the training data, and the inputs and outputs are not restricted to boolean values. As a special case our result implies one of the first positive results about learning on multi-layer neural net.s in Valiant&apos;s original PAC-learning model. At the end of this paper we will describe an efficient parallel implementation of this new learning algorit.hm. 311</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
