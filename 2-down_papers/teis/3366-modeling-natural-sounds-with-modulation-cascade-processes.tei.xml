<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Natural Sounds with Modulation Cascade Processes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Gatsby Computational Neuroscience Unit</orgName>
								<address>
									<addrLine>17 Alexandra House, Queen Square</addrLine>
									<postCode>WC1N 3AR</postCode>
									<settlement>London, London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maneesh</forename><surname>Sahani</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Gatsby Computational Neuroscience Unit</orgName>
								<address>
									<addrLine>17 Alexandra House, Queen Square</addrLine>
									<postCode>WC1N 3AR</postCode>
									<settlement>London, London</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Natural Sounds with Modulation Cascade Processes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Natural sounds are structured on many timescales. A typical segment of speech, for example, contains features that span four orders of magnitude: Sentences (∼ 1 s); phonemes (∼ 10 −1 s); glottal pulses (∼ 10 −2 s); and formants (񮽙 10 −3 s). The auditory system uses information from each of these timescales to solve complicated tasks such as auditory scene analysis [1]. One route toward understanding how auditory processing accomplishes this analysis is to build neuroscience-inspired algorithms which solve similar tasks and to compare the properties of these algorithms with properties of auditory processing. There is however a discord: Current machine-audition algorithms largely concentrate on the shorter timescale structures in sounds, and the longer structures are ignored. The reason for this is twofold. Firstly, it is a difficult technical problem to construct an algorithm that utilises both sorts of information. Secondly, it is computation-ally demanding to simultaneously process data both at high resolution (to extract short temporal information) and for long duration (to extract long temporal information). The contribution of this work is to develop a new statistical model for natural sounds that captures structure across a wide range of timescales , and to provide efficient learning and inference algorithms. We demonstrate the success of this approach on a missing data task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
