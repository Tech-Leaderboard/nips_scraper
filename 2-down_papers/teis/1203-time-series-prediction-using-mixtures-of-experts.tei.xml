<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Time Series Prediction Using Mixtures of Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Meir</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering Technion Haifa</orgName>
								<orgName type="department" key="dep3">Department of Statistics University of North Carolina Chapel Hill</orgName>
								<orgName type="laboratory">Information Systems Lab</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 32000, 27599</postCode>
									<region>CA, NC</region>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><forename type="middle">J</forename><surname>Zeevi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering Technion Haifa</orgName>
								<orgName type="department" key="dep3">Department of Statistics University of North Carolina Chapel Hill</orgName>
								<orgName type="laboratory">Information Systems Lab</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 32000, 27599</postCode>
									<region>CA, NC</region>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Adler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering Technion Haifa</orgName>
								<orgName type="department" key="dep3">Department of Statistics University of North Carolina Chapel Hill</orgName>
								<orgName type="laboratory">Information Systems Lab</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 32000, 27599</postCode>
									<region>CA, NC</region>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Time Series Prediction Using Mixtures of Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>310 A. 1. Zeevi, R. Meir and R. 1. Adler</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider the problem of prediction of stationary time series, using the architecture known as mixtures of experts (MEM). Here we suggest a mixture which blends several autoregressive models. This study focuses on some theoretical foundations of the prediction problem in this context. More precisely, it is demonstrated that this model is a universal approximator, with respect to learning the unknown prediction function. This statement is strengthened as upper bounds on the mean squared error are established. Based on these results it is possible to compare the MEM to other families of models (e.g., neural networks and state dependent models). It is shown that a degenerate version of the MEM is in fact equivalent to a neural network, and the number of experts in the architecture plays a similar role to the number of hidden units in the latter model.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
