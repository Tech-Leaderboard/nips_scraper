<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Natschiager</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Theoretical Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Mathematics Rutgers University New Brunswick</orgName>
								<orgName type="institution">Technische Universitat Graz</orgName>
								<address>
									<postCode>08903</postCode>
									<region>NJ</region>
									<country>Austria, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Maass</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Theoretical Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Mathematics Rutgers University New Brunswick</orgName>
								<orgName type="institution">Technische Universitat Graz</orgName>
								<address>
									<postCode>08903</postCode>
									<region>NJ</region>
									<country>Austria, USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><forename type="middle">D</forename><surname>Sontag</surname></persName>
							<email>so nt ag@h il bert. r ut ge rs . e du</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Theoretical Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Mathematics Rutgers University New Brunswick</orgName>
								<orgName type="institution">Technische Universitat Graz</orgName>
								<address>
									<postCode>08903</postCode>
									<region>NJ</region>
									<country>Austria, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Anthony Zador Cold Spring Harbor Laboratory 1 Bungtown Rd Cold Spring Harbor, NY 11724 za d or@cshl. org Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their &quot;weight&quot; changes on a short time scale by several hundred percent in dependence of the past input to the synapse. In this article we explore the consequences that these synaptic dynamics entail for the computational power of feedforward neural networks. We show that gradient descent suffices to approximate a given (quadratic) filter by a rather small neural system with dynamic synapses. We also compare our network model to artificial neural networks designed for time series processing. Our numerical results are complemented by theoretical analysis which show that even with just a single hidden layer such networks can approximate a surprisingly large large class of nonlinear filters: all filters that can be characterized by Volterra series. This result is robust with regard to various changes in the model for synaptic dynamics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
