<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morteza</forename><surname>Ibrahimi</surname></persName>
							<email>ibrahimi@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit2">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit3">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 94305, 94305</postCode>
									<region>CA, CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><surname>Javanmard</surname></persName>
							<email>adelj@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit2">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit3">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 94305, 94305</postCode>
									<region>CA, CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">Van</forename><surname>Roy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit2">Stanford University Stanford</orgName>
								<orgName type="institution" key="instit3">Stanford University Stanford</orgName>
								<address>
									<postCode>94305, 94305, 94305</postCode>
									<region>CA, CA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We study the problem of adaptive control of a high dimensional linear quadratic (LQ) system. Previous work established the asymptotic convergence to an optimal controller for various adaptive control schemes. More recently, for the average cost LQ problem, a regret bound of O(√ T) was shown, apart form logarithmic factors. However, this bound scales exponentially with p, the dimension of the state space. In this work we consider the case where the matrices describing the dynamic of the LQ system are sparse and their dimensions are large. We present an adaptive control scheme that achieves a regret bound of O(p √ T), apart from logarithmic factors. In particular, our algorithm has an average cost of (1 +) times the optimum cost after T = polylog(p)O(1// 2). This is in comparison to previous work on the dense dynamics where the algorithm requires time that scales exponentially with dimension in order to achieve regret of times the optimal cost. We believe that our result has prominent applications in the emerging area of computational advertising, in particular targeted online advertising and advertising in social networks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
