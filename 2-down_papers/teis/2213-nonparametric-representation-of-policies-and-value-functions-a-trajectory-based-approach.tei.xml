<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ATR Human Information Science Laboratories</orgName>
								<orgName type="institution" key="instit1">Robotics Institute</orgName>
								<orgName type="institution" key="instit2">HCII Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<addrLine>Dept. 3 Keihanna Science City Kyoto</addrLine>
									<postCode>15213, 619-0288</postCode>
									<region>PA</region>
									<country>USA, Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Morimoto</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ATR Human Information Science Laboratories</orgName>
								<orgName type="institution" key="instit1">Robotics Institute</orgName>
								<orgName type="institution" key="instit2">HCII Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<addrLine>Dept. 3 Keihanna Science City Kyoto</addrLine>
									<postCode>15213, 619-0288</postCode>
									<region>PA</region>
									<country>USA, Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A longstanding goal of reinforcement learning is to develop non-parametric representations of policies and value functions that support rapid learning without suffering from interference or the curse of di-mensionality. We have developed a trajectory-based approach, in which policies and value functions are represented nonparametrically along tra-jectories. These trajectories, policies, and value functions are updated as the value function becomes more accurate or as a model of the task is updated. We have applied this approach to periodic tasks such as hopping and walking, which required handling discount factors and discontinu-ities in the task dynamics, and using function approximation to represent value functions at discontinuities. We also describe extensions of the approach to make the policies more robust to modeling error and sensor noise.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
