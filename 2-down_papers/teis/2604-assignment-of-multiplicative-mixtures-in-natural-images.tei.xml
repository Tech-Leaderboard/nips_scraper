<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assignment of Multiplicative Mixtures in Natural Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Odelia</forename><surname>Schwartz</surname></persName>
							<email>odelia@salk.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
							<email>dayan@gatsby.ucl.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">HHMI and Salk Institute La Jolla</orgName>
								<orgName type="institution" key="instit2">HHMI and Salk Institute</orgName>
								<address>
									<addrLine>La Jolla</addrLine>
									<postCode>92014, 92014</postCode>
									<region>CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">GCNU</orgName>
								<address>
									<addrLine>UCL 17 Queen Square</addrLine>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Assignment of Multiplicative Mixtures in Natural Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In the analysis of natural images, Gaussian scale mixtures (GSM) have been used to account for the statistics of filter responses, and to inspire hierarchical cortical representational learning schemes. GSMs pose a critical assignment problem, working out which filter responses were generated by a common multiplicative factor. We present a new approach to solving this assignment problem through a probabilistic extension to the basic GSM, and show how to perform inference in the model using Gibbs sampling. We demonstrate the efficacy of the approach on both synthetic and image data. Understanding the statistical structure of natural images is an important goal for visual neuroscience. Neural representations in early cortical areas decompose images (and likely other sensory inputs) in a way that is sensitive to sophisticated aspects of their probabilistic structure. This structure also plays a key role in methods for image processing and coding. A striking aspect of natural images that has reflections in both top-down and bottom-up modeling is coordination across nearby locations, scales, and orientations. From a top-down perspective, this structure has been modeled using what is known as a Gaussian Scale Mixture model (GSM). 1-3 GSMs involve a multi-dimensional Gaussian (each dimension of which captures local structure as in a linear filter), multiplied by a spatialized collection of common hidden scale variables or mixer variables * (which capture the coordination). GSMs have wide implications in theories of cortical receptive field development, eg the comprehensive bubbles framework of Hyv√§rinen. 4 The mixer variables provide the top-down account of two bottom-up characteristics of natural image statistics, namely the &apos;bowtie&apos; statistical dependency, 5, 6 and the fact that the marginal distributions of receptive field-like filters have high kurtosis. 7, 8 In hindsight, these ideas also bear a close relationship with Ruderman and Bialek&apos;s multiplicative bottom-up image analysis framework 9 and statistical models for divisive gain control. 6 Coordinated structure has also been addressed in other image work, 10-14 and in other domains such as speech 15 and finance. 16 Many approaches to the unsupervised specification of representations in early cortical areas rely on the coordinated structure. 17-21 The idea is to learn linear filters (eg modeling simple cells as in 22, 23), and then, based on the coordination, to find combinations of these (perhaps non-linearly transformed) as a way of finding higher order filters (eg complex cells). One critical facet whose specification from data is not obvious is the neighborhood arrangement, ie which linear filters share which mixer variables. * Mixer variables are also called mutlipliers, but are unrelated to the scales of a wavelet.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
