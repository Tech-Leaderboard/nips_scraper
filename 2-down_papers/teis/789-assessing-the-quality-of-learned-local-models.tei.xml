<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assessing the Quality of Learned Local Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Brain and Cognitive Sciences</orgName>
								<orgName type="department" key="dep2">Institute of Technology 545 Technology Square</orgName>
								<orgName type="laboratory">The Artifical Intelligence Laboratory Massachusetts</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Brain and Cognitive Sciences</orgName>
								<orgName type="department" key="dep2">Institute of Technology 545 Technology Square</orgName>
								<orgName type="laboratory">The Artifical Intelligence Laboratory Massachusetts</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Assessing the Quality of Learned Local Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>An approach is presented to learning high dimensional functions in the case where the learning algorithm can affect the generation of new data. A local modeling algorithm, locally weighted regression, is used to represent the learned function. Architectural parameters of the approach, such as distance metrics, are also localized and become a function of the query point instead of being global. Statistical tests are given for when a local model is good enough and sampling should be moved to a new area. Our methods explicitly deal with the case where prediction accuracy requirements exist during exploration: By gradually shifting a &quot;center of exploration&quot; and controlling the speed of the shift with local prediction accuracy, a goal-directed exploration of state space takes place along the fringes of the current data support until the task goal is achieved. We illustrate this approach with simulation results and results from a real robot learning a complex juggling task. 1 INTRODUCTION Every learning algorithm faces the problem of sparse data if the task to be learned is sufficiently nonlinear and high dimensional. Generalization from a limited number of data points in such spaces will usually be strongly biased. If, however, the learning algorithm has the ability to affect the creation of new experiences, the need for such bias can be reduced. This raises the questions of (1) how to sample data the most efficient, and (2) how to assess the quality of the sampled data with respect to the task to be learned. To address these questions, we represent the task to be learned with local linear models. Instead of constraining the number of linear models as in other approaches, infinitely many local models are permitted. This corresponds to modeling the task with the help of (hyper-) tangent planes at every query point instead of representing it in a piecewise linear fashion. The algorithm applied for this purpose, locally weighted regression (L WR), stems from nonparametric regression analysis (Cleveland, 1979, Muller, 1988, Hardie 1990, Hastie&amp;Tibshirani, 1991). In Section 2, we will briefly outline LWR. Section 3 discusses 160</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
