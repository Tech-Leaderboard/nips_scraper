<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Testing and Learning on Distributions with Symmetric Noise Invariance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ho</forename><surname>Chung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics University Of Oxford</orgName>
								<orgName type="department" key="dep2">Department of Statistics University Of Oxford</orgName>
								<orgName type="laboratory">Centre for Computational Biology University of Birmingham</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Law</surname></persName>
							<email>hlaw@stats.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics University Of Oxford</orgName>
								<orgName type="department" key="dep2">Department of Statistics University Of Oxford</orgName>
								<orgName type="laboratory">Centre for Computational Biology University of Birmingham</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Yau</surname></persName>
							<email>c.yau@bham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics University Of Oxford</orgName>
								<orgName type="department" key="dep2">Department of Statistics University Of Oxford</orgName>
								<orgName type="laboratory">Centre for Computational Biology University of Birmingham</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Sejdinovic</surname></persName>
							<email>dino.sejdinovic@stats.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics University Of Oxford</orgName>
								<orgName type="department" key="dep2">Department of Statistics University Of Oxford</orgName>
								<orgName type="laboratory">Centre for Computational Biology University of Birmingham</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Testing and Learning on Distributions with Symmetric Noise Invariance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Kernel embeddings of distributions and the Maximum Mean Discrepancy (MMD), the resulting distance between distributions, are useful tools for fully nonparametric two-sample testing and learning on distributions. However, it is rare that all possible differences between samples are of interest-discovered differences can be due to different types of measurement noise, data collection artefacts or other irrelevant sources of variability. We propose distances between distributions which encode invariance to additive symmetric noise, aimed at testing whether the assumed true underlying processes differ. Moreover, we construct invariant features of distributions, leading to learning algorithms robust to the impairment of the input distributions with symmetric additive noise.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
