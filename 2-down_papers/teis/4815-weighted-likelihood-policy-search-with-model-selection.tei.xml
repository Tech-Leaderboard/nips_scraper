<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weighted Likelihood Policy Search with Model Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuyoshi</forename><surname>Ueno</surname></persName>
							<email>ueno@ar.sanken.osaka-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Japan Science and Technology Agency</orgName>
								<orgName type="institution" key="instit2">University of Tokyo</orgName>
								<orgName type="institution" key="instit3">Osaka University</orgName>
								<orgName type="institution" key="instit4">Osaka University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Hayashi</surname></persName>
							<email>hayashi.kohei@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Japan Science and Technology Agency</orgName>
								<orgName type="institution" key="instit2">University of Tokyo</orgName>
								<orgName type="institution" key="instit3">Osaka University</orgName>
								<orgName type="institution" key="instit4">Osaka University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Washio</surname></persName>
							<email>washio@ar.sanken.osaka-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Japan Science and Technology Agency</orgName>
								<orgName type="institution" key="instit2">University of Tokyo</orgName>
								<orgName type="institution" key="instit3">Osaka University</orgName>
								<orgName type="institution" key="instit4">Osaka University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshinobu</forename><surname>Kawahara</surname></persName>
							<email>kawahara@ar.sanken.osaka-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Japan Science and Technology Agency</orgName>
								<orgName type="institution" key="instit2">University of Tokyo</orgName>
								<orgName type="institution" key="instit3">Osaka University</orgName>
								<orgName type="institution" key="instit4">Osaka University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Weighted Likelihood Policy Search with Model Selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Reinforcement learning (RL) methods based on direct policy search (DPS) have been actively discussed to achieve an efficient approach to complicated Markov decision processes (MDPs). Although they have brought much progress in practical applications of RL, there still remains an unsolved problem in DPS related to model selection for the policy. In this paper, we propose a novel DPS method, weighted likelihood policy search (WLPS), where a policy is efficiently learned through the weighted likelihood estimation. WLPS naturally connects DPS to the statistical inference problem and thus various sophisticated techniques in statistics can be applied to DPS problems directly. Hence, by following the idea of the information criterion, we develop a new measurement for model comparison in DPS based on the weighted log-likelihood.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
