<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Time-Warping Network: A Hybrid Framework for Speech Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">AT&amp;T Bell Laboratories Speech Research Department Murray Hill</orgName>
								<address>
									<postCode>00974</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">AT&amp;T Bell Laboratories Speech Research Department Murray Hill</orgName>
								<address>
									<postCode>00974</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Time-Warping Network: A Hybrid Framework for Speech Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Enrico Bocchieri Recently. much interest has been generated regarding speech recognition systems based on Hidden Markov Models (HMMs) and neural network (NN) hybrids. Such systems attempt to combine the best features of both models: the temporal structure of HMMs and the discriminative power of neural networks. In this work we define a time-warping (1W) neuron that extends the operation of the fonnal neuron of a back-propagation network by warping the input pattern to match it optimally to its weights. We show that a single-layer network of TW neurons is equivalent to a Gaussian density HMM-based recognition system. and we propose to improve the discriminative power of this system by using back-propagation discriminative training. and/or by generalizing the structure of the recognizer to a multi-layered net The performance of the proposed network was evaluated on a highly confusable, isolated word. multi speaker recognition task. The results indicate that not only does the recognition performance improve. but the separation between classes is enhanced also, allowing us to set up a rejection criterion to improve the confidence of the system. L INTRODUCTION Since their first application in speech recognition systems in the late seventies, hidden Markov models have been established as a most useful tool. mainly due to their ability to handle the sequential dynamical nature of the speech signal. With the revival of connectionism in the mid-eighties. considerable interest arose in applying artificial neural networks for speech recognition. This interest was based on the discriminative power of NNs and their ability to deal with non-explicit knowledge. These two paradigms. namely HMM and NN. inspired by different philosophies. were seen at first as different and competing tools. Recently. links have been established between these two paradigms. aiming at a hybrid framework in which the advantages of the two models can be combined. For example. Bourlard and Wellekens [1] showed that neural 151</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
