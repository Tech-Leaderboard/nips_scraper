<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analytical study of the interplay between architecture and predictability</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avner</forename><surname>Priel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="institution" key="instit1">Minerva Center</orgName>
								<orgName type="institution" key="instit2">Bar Ilan University</orgName>
								<address>
									<addrLine>Ramat-Gan 52900</addrLine>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Kanter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="institution" key="instit1">Minerva Center</orgName>
								<orgName type="institution" key="instit2">Bar Ilan University</orgName>
								<address>
									<addrLine>Ramat-Gan 52900</addrLine>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Kessler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="institution" key="instit1">Minerva Center</orgName>
								<orgName type="institution" key="instit2">Bar Ilan University</orgName>
								<address>
									<addrLine>Ramat-Gan 52900</addrLine>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analytical study of the interplay between architecture and predictability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We study model feed forward networks as time series predictors in the stationary limit. The focus is on complex, yet non-chaotic, behavior. The main question we address is whether the asymptotic behavior is governed by the architecture, regardless the details of the weights. We find hierarchies among classes of architectures with respect to the attract or dimension of the long term sequence they are capable of generating; larger number of hidden units can generate higher dimensional attractors. In the case of a perceptron, we develop the stationary solution for general weights, and show that the flow is typically one dimensional. The relaxation time from an arbitrary initial condition to the stationary solution is found to scale linearly with the size of the network. In multilayer networks, the number of hidden units gives bounds on the number and dimension of the possible attractors. We conclude that long term prediction (in the non-chaotic regime) with such models is governed by attractor dynamics related to the architecture. Neural networks provide an important tool as model free estimators for the solution of problems when the real model is unknown, or weakly known. In the last decade there has been a growing interest in the application of such tools in the area of time series prediction (see Weigand and Gershenfeld, 1994). In this paper we analyse a typical class of architectures used in this field, i.e. a feed forward network governed by the following dynamic rule: S t+l S 1 = out ; S t+l = st 1 J&apos;-2 N ] ]-, ... , (1) where Sout is the network&apos;s output at time step t and Sj are the inputs at that time; N is the size of the delayed input vector. The rational behind using time delayed vectors as inputs is the theory of state space reconstruction of a dynamic system</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
