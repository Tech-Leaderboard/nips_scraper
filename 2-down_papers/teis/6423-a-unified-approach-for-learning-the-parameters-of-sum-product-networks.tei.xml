<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified Approach for Learning the Parameters of Sum-Product Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
							<email>han.zhao@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Dept</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="department" key="dep3">Machine Learning Dept</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">University of Waterloo</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
							<email>ppoupart@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Dept</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="department" key="dep3">Machine Learning Dept</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">University of Waterloo</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Gordon</surname></persName>
							<email>ggordon@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Machine Learning Dept</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<orgName type="department" key="dep3">Machine Learning Dept</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">University of Waterloo</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified Approach for Learning the Parameters of Sum-Product Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a unified approach for learning the parameters of Sum-Product networks (SPNs). We prove that any complete and decomposable SPN is equivalent to a mixture of trees where each tree corresponds to a product of univariate distributions. Based on the mixture model perspective, we characterize the objective function when learning SPNs based on the maximum likelihood estimation (MLE) principle and show that the optimization problem can be formulated as a signomial program. We construct two parameter learning algorithms for SPNs by using sequential monomial approximations (SMA) and the concave-convex procedure (CCCP), respectively. The two proposed methods naturally admit multiplicative updates, hence effectively avoiding the projection operation. With the help of the unified framework, we also show that, in the case of SPNs, CCCP leads to the same algorithm as Expectation Maximization (EM) despite the fact that they are different in general.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
