<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multivariate f-Divergence Estimation With Confidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">R</forename><surname>Moon</surname></persName>
							<email>krmoon@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="institution" key="instit1">EECS University of Michigan Ann Arbor</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><forename type="middle">O</forename><surname>Hero</surname></persName>
							<email>hero@eecs.umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="institution" key="instit1">EECS University of Michigan Ann Arbor</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="institution" key="instit1">EECS University of Michigan Ann Arbor</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI, MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multivariate f-Divergence Estimation With Confidence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The problem of f-divergence estimation is important in the fields of machine learning, information theory, and statistics. While several nonparametric divergence estimators exist, relatively few have known convergence properties. In particular , even for those estimators whose MSE convergence rates are known, the asymptotic distributions are unknown. We establish the asymptotic normality of a recently proposed ensemble estimator of f-divergence between two distributions from a finite number of samples. This estimator has MSE convergence rate of O 1 T , is simple to implement, and performs well in high dimensions. This theory enables us to perform divergence-based inference tasks such as testing equality of pairs of distributions based on empirical samples. We experimentally validate our theoretical results and, as an illustration, use them to empirically bound the best achievable classification error.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
