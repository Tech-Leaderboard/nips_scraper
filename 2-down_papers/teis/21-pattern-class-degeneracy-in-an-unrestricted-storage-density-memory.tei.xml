<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">P A &apos;ITERN CLASS DEGENERACY IN AN UNRESTRICfED STORAGE DENSITY MEMORY</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">L</forename><surname>Scofield</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nestor, Inc</orgName>
								<address>
									<addrLine>1 Richmond Square</addrLine>
									<postCode>02906</postCode>
									<settlement>Providence, Rhode Island</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">L</forename><surname>Reilly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nestor, Inc</orgName>
								<address>
									<addrLine>1 Richmond Square</addrLine>
									<postCode>02906</postCode>
									<settlement>Providence, Rhode Island</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elbaum</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nestor, Inc</orgName>
								<address>
									<addrLine>1 Richmond Square</addrLine>
									<postCode>02906</postCode>
									<settlement>Providence, Rhode Island</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><forename type="middle">N</forename><surname>Cooper</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nestor, Inc</orgName>
								<address>
									<addrLine>1 Richmond Square</addrLine>
									<postCode>02906</postCode>
									<settlement>Providence, Rhode Island</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">P A &apos;ITERN CLASS DEGENERACY IN AN UNRESTRICfED STORAGE DENSITY MEMORY</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>674</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The study of distributed memory systems has produced a number of models which work well in limited domains. However, until recently, the application of such systems to real-world problems has been difficult because of storage limitations, and their inherent architectural (and for serial simulation, computational) complexity. Recent development of memories with unrestricted storage capacity and economical feedforward architectures has opened the way to the application of such systems to complex pattern recognition problems. However, such problems are sometimes underspecified by the features which describe the environment, and thus a significant portion of the pattern environment is often non-separable. We will review current work on high density memory systems and their network implementations. We will discuss a general learning algorithm for such high density memories and review its application to separable point sets. Finally, we will introduce an extension of this method for learning the probability distributions of non-separable point sets. INTRODUcnON Information storage in distributed content addressable memories has long been the topic of intense study. Early research focused on the development of correlation matrix memories 1, 2, 3, 4. Workers in the field found that memories of this sort allowed storage of a number of distinct memories no larger than the number of dimensions of the input space. Further storage beyond this number caused the system to give an incorrect output for a memorized input.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
