<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Yuhas, Goldstein</roleName><forename type="first">Jenkins</forename><surname>Sejnowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Salk Institute and Department of Biology</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">The Applied Physics Laboratory The Johns Hopkins University Laurel</orgName>
								<orgName type="institution" key="instit1">The University of California at San Diego San Diego</orgName>
								<orgName type="institution" key="instit2">The Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>92037, 21218, 20707</postCode>
									<region>CA, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Salk Institute and Department of Biology</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">The Applied Physics Laboratory The Johns Hopkins University Laurel</orgName>
								<orgName type="institution" key="instit1">The University of California at San Diego San Diego</orgName>
								<orgName type="institution" key="instit2">The Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>92037, 21218, 20707</postCode>
									<region>CA, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Yuhas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Salk Institute and Department of Biology</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">The Applied Physics Laboratory The Johns Hopkins University Laurel</orgName>
								<orgName type="institution" key="instit1">The University of California at San Diego San Diego</orgName>
								<orgName type="institution" key="instit2">The Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>92037, 21218, 20707</postCode>
									<region>CA, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Goldstein</surname><genName>Jr</genName></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Salk Institute and Department of Biology</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">The Applied Physics Laboratory The Johns Hopkins University Laurel</orgName>
								<orgName type="institution" key="instit1">The University of California at San Diego San Diego</orgName>
								<orgName type="institution" key="instit2">The Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>92037, 21218, 20707</postCode>
									<region>CA, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abstract</forename><forename type="middle">R E</forename><surname>Jenkins</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Salk Institute and Department of Biology</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">The Applied Physics Laboratory The Johns Hopkins University Laurel</orgName>
								<orgName type="institution" key="instit1">The University of California at San Diego San Diego</orgName>
								<orgName type="institution" key="instit2">The Johns Hopkins University Baltimore</orgName>
								<address>
									<postCode>92037, 21218, 20707</postCode>
									<region>CA, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>232</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Acoustic speech recognition degrades in the presence of noise. Compensatory information is available from the visual speech signals around the speaker&apos;s mouth. Previous attempts at using these visual speech signals to improve automatic speech recognition systems have combined the acoustic and visual speech information at a symbolic level using heuristic rules. In this paper, we demonstrate an alternative approach to fusing the visual and acoustic speech information by training feedforward neural networks to map the visual signal onto the corresponding short-term spectral amplitude envelope (STSAE) of the acoustic signal. This information can be directly combined with the degraded acoustic STSAE. Significant improvements are demonstrated in vowel recognition from noise-degraded acoustic signals. These results are compared to the performance of humans, as well as other pattern matching and estimation algorithms.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
