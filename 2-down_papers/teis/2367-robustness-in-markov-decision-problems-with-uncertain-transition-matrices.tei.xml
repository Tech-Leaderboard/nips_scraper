<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robustness in Markov Decision Problems with Uncertain Transition Matrices *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Nilim</surname></persName>
							<email>nilim@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of EECS</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
								<address>
									<postCode>94720, 94720</postCode>
									<region>CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
							<email>elghaoui@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of EECS</orgName>
								<orgName type="department" key="dep2">Department of EECS</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
								<address>
									<postCode>94720, 94720</postCode>
									<region>CA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robustness in Markov Decision Problems with Uncertain Transition Matrices *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Optimal solutions to Markov Decision Problems (MDPs) are very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of those probabilities is far from accurate. Hence, estimation errors are limiting factors in applying MDPs to real-world problems. We propose an algorithm for solving finite-state and finite-action MDPs, where the solution is guaranteed to be robust with respect to estimation errors on the state transition probabilities. Our algorithm involves a statistically accurate yet numerically efficient representation of uncertainty, via Kullback-Leibler divergence bounds. The worst-case complexity of the robust algorithm is the same as the original Bellman recursion. Hence, robustness can be added at practically no extra computing cost.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
