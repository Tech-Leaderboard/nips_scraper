<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nonlinear directed acyclic structure learning with weakly additive noise models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Tillman</surname></persName>
							<email>rtillman@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">MPI for Biological Cybernetics Pittsburgh</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
							<email>arthur.gretton@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">MPI for Biological Cybernetics Pittsburgh</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MPI for Biological Cybernetics Pittsburgh</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University Pittsburgh</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA, PA, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nonlinear directed acyclic structure learning with weakly additive noise models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The recently proposed additive noise model has advantages over previous directed structure learning approaches since it (i) does not assume linearity or Gaussianity and (ii) can discover a unique DAG rather than its Markov equivalence class. However, for certain distributions, e.g. linear Gaussians, the additive noise model is invertible and thus not useful for structure learning, and it was originally proposed for the two variable case with a multivariate extension which requires enumerating all possible DAGs. We introduce weakly additive noise models, which extends this framework to cases where the additive noise model is invertible and when additive noise is not present. We then provide an algorithm that learns an equivalence class for such models from data, by combining a PC style search using recent advances in kernel measures of conditional dependence with local searches for additive noise models in substructures of the Markov equivalence class. This results in a more computationally efficient approach that is useful for arbitrary distributions even when additive noise models are invertible.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
