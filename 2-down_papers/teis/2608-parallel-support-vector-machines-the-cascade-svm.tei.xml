<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parallel Support Vector Machines: The Cascade SVM</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Peter</forename><surname>Graf</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC</orgName>
								<address>
									<addrLine>Laboratories 4 Independence Way</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Cosatto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC</orgName>
								<address>
									<addrLine>Laboratories 4 Independence Way</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC</orgName>
								<address>
									<addrLine>Laboratories 4 Independence Way</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Durdanovic</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC</orgName>
								<address>
									<addrLine>Laboratories 4 Independence Way</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NEC</orgName>
								<address>
									<addrLine>Laboratories 4 Independence Way</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parallel Support Vector Machines: The Cascade SVM</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We describe an algorithm for support vector machines (SVM) that can be parallelized efficiently and scales to very large problems with hundreds of thousands of training vectors. Instead of analyzing the whole training set in one optimization step, the data are split into subsets and optimized separately with multiple SVMs. The partial results are combined and filtered again in a &apos;Cascade&apos; of SVMs, until the global optimum is reached. The Cascade SVM can be spread over multiple processors with minimal communication overhead and requires far less memory, since the kernel matrices are much smaller than for a regular SVM. Convergence to the global optimum is guaranteed with multiple passes through the Cascade, but already a single pass provides good generalization. A single pass is 5x-10x faster than a regular SVM for problems of 100,000 vectors when implemented on a single processor. Parallel implementations on a cluster of 16 processors were tested with over 1 million vectors (2-class problems), converging in a day or two, while a regular SVM never converged in over a week.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
