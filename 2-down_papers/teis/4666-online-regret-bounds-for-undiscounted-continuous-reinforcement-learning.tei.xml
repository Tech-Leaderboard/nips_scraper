<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/melina/Documents/js/scrape/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-02-21T06:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Regret Bounds for Undiscounted Continuous Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Ortner</surname></persName>
							<email>rortner@unileoben.ac.at</email>
							<affiliation key="aff0">
								<orgName type="laboratory">† INRIA Lille-Nord Europe, ´ equipe SequeL</orgName>
								<address>
									<addrLine>59650 Villeneuve d&apos;Ascq</addrLine>
									<postCode>8700</postCode>
									<settlement>Leoben</settlement>
									<country>Austria, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Montanuniversitaet</forename><surname>Leoben</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">† INRIA Lille-Nord Europe, ´ equipe SequeL</orgName>
								<address>
									<addrLine>59650 Villeneuve d&apos;Ascq</addrLine>
									<postCode>8700</postCode>
									<settlement>Leoben</settlement>
									<country>Austria, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Ryabko</surname></persName>
							<email>daniil@ryabko.net</email>
							<affiliation key="aff0">
								<orgName type="laboratory">† INRIA Lille-Nord Europe, ´ equipe SequeL</orgName>
								<address>
									<addrLine>59650 Villeneuve d&apos;Ascq</addrLine>
									<postCode>8700</postCode>
									<settlement>Leoben</settlement>
									<country>Austria, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online Regret Bounds for Undiscounted Continuous Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We derive sublinear regret bounds for undiscounted reinforcement learning in continuous state space. The proposed algorithm combines state aggregation with the use of upper confidence bounds for implementing optimism in the face of uncertainty. Beside the existence of an optimal policy which satisfies the Poisson equation , the only assumptions made are Hölder continuity of rewards and transition probabilities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI>
